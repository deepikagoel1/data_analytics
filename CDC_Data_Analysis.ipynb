{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe: (314540, 5)\n",
      "Grouped Data (309997, 9)\n",
      "dict_keys(['Sheet1'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import editdistance\n",
    "import numpy as np\n",
    "\n",
    "# Read Excel file and iterate over each sheet\n",
    "excel_file = \"cdc_2021.xlsx\"\n",
    "sheet_names = pd.ExcelFile(excel_file).sheet_names\n",
    "\n",
    "dfs = {}  # Dictionary to store dataframes for each sheet\n",
    "for sheet_name in sheet_names:\n",
    "    df = pd.read_excel(excel_file, sheet_name=sheet_name)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df = df[['RegNo', 'Name', \"FatherName\", \"MotherName\", \"DOB\"]]\n",
    "    df[\"Name\"] = df[\"Name\"].str.strip().str.title().sort_values(ascending=True)\n",
    "    df[\"FatherName\"] = df[\"FatherName\"].str.strip().str.title().sort_values(ascending=True)\n",
    "    df[\"MotherName\"] = df[\"MotherName\"].str.strip().str.title().sort_values(ascending=True)\n",
    "    df[\"DOB\"] = df[\"DOB\"].astype(str)\n",
    "    df.dropna(subset=['Name', 'FatherName', 'MotherName'], inplace=True)\n",
    "\n",
    "    print(f\"Dataframe: {df.shape}\")\n",
    "    \n",
    "    grouped_df = df.groupby(\"RegNo\").agg({\n",
    "        \"Name\": lambda x: '|'.join(x.unique()),\n",
    "        \"DOB\": lambda x: '|'.join(x.unique()),\n",
    "        \"FatherName\": lambda x: '|'.join(x.unique()),\n",
    "        \"MotherName\": lambda x: '|'.join(x.unique())\n",
    "    }).reset_index()\n",
    "    \n",
    "    grouped_df[\"Unique_Count_Name\"] = df.groupby(\"RegNo\")[\"Name\"].nunique().values\n",
    "    grouped_df[\"Unique_Count_DOB\"] = df.groupby(\"RegNo\")[\"DOB\"].nunique().values\n",
    "    grouped_df[\"Unique_Count_FatherName\"] = df.groupby(\"RegNo\")[\"FatherName\"].nunique().values\n",
    "    grouped_df[\"Unique_Count_MotherName\"] = df.groupby(\"RegNo\")[\"MotherName\"].nunique().values\n",
    "\n",
    "    grouped_df[\"Name\"] = grouped_df[\"Name\"].astype(str)\n",
    "    grouped_df[\"DOB\"] = grouped_df[\"DOB\"].astype(str)\n",
    "    grouped_df[\"FatherName\"] = grouped_df[\"FatherName\"].astype(str)\n",
    "    grouped_df[\"MotherName\"] = grouped_df[\"MotherName\"].astype(str)\n",
    "    \n",
    "    print(\"Grouped Data\", grouped_df.shape)\n",
    "\n",
    "    for col in [\"Name\", \"FatherName\", \"MotherName\", \"DOB\"]:\n",
    "        max_count = grouped_df[f\"Unique_Count_{col}\"].max()\n",
    "        for i in range(1, max_count + 1):\n",
    "            grouped_df[f\"{col}{i}\"] = grouped_df[col].str.split('|', expand=True)[i - 1]\n",
    "            # if grouped_df[f\"Unique_Count_{col}\"].nunique() == 1 or i > grouped_df[f\"Unique_Count_{col}\"].nunique():\n",
    "            #     grouped_df.loc[:, f'{col}{i}':] = None\n",
    "        grouped_df[f\"Flag_{col}\"] = 0\n",
    "    \n",
    "    grouped_df.drop([\"Name\", \"FatherName\", \"MotherName\", \"DOB\"], axis=1, inplace=True)\n",
    "    \n",
    "    dfs[sheet_name] = grouped_df\n",
    "\n",
    "# print(\"DFS\" , dfs[\"One\"].shape)\n",
    "# print(\"DFS\" , dfs[\"Two\"].shape)\n",
    "# print(\"DFS\" , dfs[\"Three\"].shape)\n",
    "# print(\"DFS\" , dfs[\"Four\"].shape)\n",
    "\n",
    "\n",
    "# Now you can access each dataframe using sheet names as keys in the dfs dictionary\n",
    "print(dfs.keys())  # To see the names of dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import editdistance\n",
    "\n",
    "# Function to calculate character changes between two names\n",
    "def calculate_character_changes(**kwargs):\n",
    "    original_name = kwargs.get('original_name', '')\n",
    "    mismatched_name = kwargs.get('mismatched_name', '')\n",
    "    col_name = kwargs.get('col_name', '')\n",
    "\n",
    "    if mismatched_name is None:\n",
    "        mismatched_name = original_name\n",
    "\n",
    "    original_words = sorted(original_name.strip().split())\n",
    "    mismatched_words = sorted(mismatched_name.strip().split())\n",
    "    sorted_original = ' '.join(original_words)\n",
    "    sorted_mismatched = ' '.join(mismatched_words)\n",
    "    sorted_distance = editdistance.eval(sorted_original, sorted_mismatched)\n",
    "    modified_distance = editdistance.eval(original_name.replace(\" \", \"\"), mismatched_name.replace(\" \", \"\"))\n",
    "    max_distance = max(len(original_name), len(mismatched_name))\n",
    "\n",
    "    entire_mismatch = 0\n",
    "\n",
    "    if set(sorted_original) != set(sorted_mismatched):\n",
    "        entire_mismatch = 1  # Set entire mismatch flag to 1\n",
    "        # print(f\"{sorted_original},{sorted_mismatched}, {entire_mismatch}\")\n",
    "\n",
    "    if sorted_distance == 0:\n",
    "        modified_distance = 0\n",
    "        max_distance = 0\n",
    "    else:\n",
    "        if sorted_original != sorted_mismatched:\n",
    "            max_distance = max(len(original_name), len(mismatched_name))\n",
    "        if modified_distance < sorted_distance:\n",
    "            sorted_distance = modified_distance\n",
    "            \n",
    "    return sorted_distance, entire_mismatch, col_name\n",
    "\n",
    "# Iterate over each dataframe in dfs dictionary\n",
    "for sheet_name, df in dfs.items():\n",
    "    for col in [\"Name\", \"FatherName\", \"MotherName\", \"DOB\"]:\n",
    "        max_count = df[f\"Unique_Count_{col}\"].max()\n",
    "        \n",
    "        # Iterate over the columns associated with the current name category\n",
    "        for i in range(2, max_count + 1):\n",
    "            mismatched_col_name = f\"{col}{i}\"\n",
    "            \n",
    "            # Ensure the column exists in the dataframe\n",
    "            if mismatched_col_name in df.columns:\n",
    "                original_col_name = f\"{col}1\"\n",
    "                original_values = df[original_col_name]\n",
    "                mismatched_values = df[mismatched_col_name]\n",
    "                \n",
    "                # Calculate character differences for each pair of original and mismatched values\n",
    "                sorted_distances = []\n",
    "                entire_mismatches = []\n",
    "                \n",
    "                for original_value, mismatched_value in zip(original_values, mismatched_values):\n",
    "                    sorted_distance, entire_mismatch, _ = calculate_character_changes(\n",
    "                        original_name=original_value,\n",
    "                        mismatched_name=mismatched_value,\n",
    "                        col_name=mismatched_col_name\n",
    "                    )\n",
    "                    sorted_distances.append(sorted_distance)\n",
    "                    entire_mismatches.append(entire_mismatch)\n",
    "                \n",
    "                # Add columns for character differences\n",
    "                df[f\"{col}_Char_Sorted_Diff_{i}\"] = sorted_distances\n",
    "                df[f\"{col}_Entire_Mismatch_{i}\"] = entire_mismatches\n",
    "                \n",
    "    # Update the dataframe in the dfs dictionary\n",
    "    dfs[sheet_name] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs1 = dfs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs[\"One\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs[\"Four\"]['Name_Entire_Mismatch_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheet_name, df in dfs.items():\n",
    "    for col in [\"Name\", \"FatherName\", \"MotherName\", \"DOB\"]:\n",
    "        max_count = df[f\"Unique_Count_{col}\"].max()\n",
    "\n",
    "        # Initialize the flag column\n",
    "        df[f\"Flag_{col}\"] = 0\n",
    "\n",
    "        # Iterate over the columns associated with the current name category\n",
    "        for i in range(2, max_count + 1):\n",
    "            sorted_diff_col_name = f\"{col}_Char_Sorted_Diff_{i}\"\n",
    "            \n",
    "            \n",
    "            # Ensure the column exists in the dataframe\n",
    "            if sorted_diff_col_name in df.columns:\n",
    "                # Update the flag column based on the character differences\n",
    "                df[f\"Flag_{col}\"] |= df[sorted_diff_col_name].apply(lambda x: 1 if x >= 1 else 0)\n",
    "    \n",
    "    # Update the dataframe in the dfs dictionary\n",
    "    dfs[sheet_name] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs2 = dfs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs[\"Four\"][\"Flag_Name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheet_name, df in dfs.items():\n",
    "    final_status_sum = 0  # Initialize sum for Final_Status\n",
    "    \n",
    "    for col in [\"Name\", \"FatherName\", \"MotherName\", \"DOB\"]:\n",
    "        final_status_sum += df[f\"Flag_{col}\"]  # Accumulate sum of Flag columns\n",
    "        \n",
    "    # Assign the total sum to the \"Final_Status\" column\n",
    "    df[\"Final_Status\"] = final_status_sum\n",
    "    \n",
    "    # Update the dataframe in the dfs dictionary\n",
    "    dfs[sheet_name] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs3 = dfs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs[\"One\"][\"Final_Status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming dfs is your dictionary of DataFrames\n",
    "for sheet_name, df in dfs.items():\n",
    "    new_dfs = []  # List to store reordered DataFrames for each column\n",
    "    \n",
    "    # Extract 'RegNo' column once\n",
    "    regno_df = df[['RegNo']]\n",
    "    final_df = df[[\"Final_Status\"]]    \n",
    "    for col in [\"Name\", \"FatherName\", \"MotherName\", \"DOB\"]:\n",
    "        # Check if the column exists in df\n",
    "        if f\"Unique_Count_{col}\" in df.columns:\n",
    "            max_count = df[f\"Unique_Count_{col}\"].max()\n",
    "            \n",
    "            # Define the desired order of columns\n",
    "            columns_order = [f'{col}{i}' for i in range(1, max_count + 1)] + \\\n",
    "                            [f'{col}_Char_Sorted_Diff_{i}' for i in range(2, max_count + 1)] + \\\n",
    "                            [f'{col}_Entire_Mismatch_{i}' for i in range(2, max_count + 1)] + \\\n",
    "                            [f'Unique_Count_{col}'] + \\\n",
    "                            [f'Flag_{col}' ] \n",
    "            \n",
    "            # Reorder the columns using loc\n",
    "            reordered_df = df.loc[:, columns_order]\n",
    "            \n",
    "            # Append the reordered DataFrame to the list\n",
    "            new_dfs.append(reordered_df)\n",
    "    \n",
    "    # Concatenate all reordered DataFrames along the columns axis\n",
    "    if new_dfs:\n",
    "        concatenated_df = pd.concat(new_dfs, axis=1)\n",
    "        new_df = pd.concat([regno_df, concatenated_df, final_df], axis=1)\n",
    "    else:\n",
    "        new_df = df\n",
    "    \n",
    "    # Update the dataframe in the dfs dictionary\n",
    "    dfs[sheet_name] = new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs[\"One\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframes have been saved to 'cdc_2021_data_analysis.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "# Specify the output Excel file path\n",
    "output_excel_file = \"cdc_2021_data_analysis.xlsx\"\n",
    "\n",
    "# Create a Pandas Excel writer object\n",
    "with pd.ExcelWriter(output_excel_file) as writer:\n",
    "    # Iterate over the dictionary of dataframes\n",
    "    for sheet_name, df in dfs.items():\n",
    "        \n",
    "        # Write each dataframe to a separate sheet in the Excel file\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "# Confirm that the Excel file has been saved\n",
    "print(f\"Dataframes have been saved to '{output_excel_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
